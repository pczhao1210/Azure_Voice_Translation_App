# 服务器运行端口
# 可在后端以 HTTP + WebSocket 服务的形式提供接口
PORT=3001

# Azure Speech 服务基础配置示例
# 出于安全考虑，前端仍会提示用户手动输入 Key、Region，本示例仅说明字段格式。
# 若在测试环境中设置这些变量，前端会在加载时自动填充默认值。
# 若希望在服务器端持久化，可将这些变量复制到 server/.env 并在代码中读取。
AZURE_SPEECH_KEY=请替换为AzureSpeechKey
AZURE_SPEECH_REGION=eastasia

# 源语音识别语言（SpeechRecognitionLanguage）
# 对应 SpeechTranslationConfig.speechRecognitionLanguage。
# 使用完整 locale 代码，如 en-US（美式英语）、zh-CN（普通话）。
# 参考列表：https://aka.ms/speech/sttt-languages
DEFAULT_FROM_LANGUAGE=en-US

# 翻译目标语言列表（逗号分隔）
# 对应 SpeechTranslationConfig.addTargetLanguage，可配置多个。
# 使用语言代码（非 locale），如 zh-Hans、en、fr。
# 多个语言用英文逗号分隔。
DEFAULT_TARGET_LANGUAGES=en

# 目标语音合成音色（VoiceName/SpeechSynthesisVoiceName）
# 对应 SpeechTranslationConfig.voiceName 或 SpeechConfig.speechSynthesisVoiceName。
# 必须选择与目标语言一致的 Neural Voice。
# 可用音色列表：https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=tts
DEFAULT_VOICE=zh-CN-XiaoxiaoNeural

# 语音合成输出格式（可选）
# 对应 SpeechTranslationConfig.setSpeechSynthesisOutputFormat。
# 例如 Raw24Khz16BitMonoPcm、Riff16Khz16BitMonoPcm。
# 完整枚举参考：SpeechSynthesisOutputFormat
DEFAULT_SPEECH_SDK_OUTPUT_FORMAT=Raw24Khz16BitMonoPcm

# 自动识别源语言配置（可选）
# 使用 AutoDetectSourceLanguageConfig.FromLanguages 时传入的候选列表
# 未启用可留空；开启时例如 "en-US,zh-CN"
DEFAULT_AUTO_DETECT_SOURCE_LANGUAGES=en-US,zh-CN

# 支持的源语言选项（下拉菜单），格式 code:显示名称，逗号分隔
# 供前端展示以及手动选择固定识别语言
SUPPORTED_FROM_LANGUAGES=en-US:英语 (美国),zh-CN:中文 (普通话),ja-JP:日语,fr-FR:法语,de-DE:德语

# 支持的目标语言选项（下拉菜单），格式 code:显示名称，逗号分隔
# 供前端展示翻译目标列表
SUPPORTED_TARGET_LANGUAGES=en:英语,zh-Hans:中文 (简体),ja:日语,fr:法语,de:德语

# Speech SDK 高级属性配置（可选）
# 对应 SpeechConfig/TranslationRecognizer.setProperty(PropertyId, value)。
# 示例：
#   PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs=4000   （静音超时）
#   PropertyId.SpeechServiceResponse_ProfanityOption=masked       （脏话过滤）
# 多项配置使用分号分隔，键名需使用完整枚举常量字符串。
DEFAULT_SPEECH_SDK_PROPERTIES=PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs=4000;PropertyId.SpeechServiceResponse_ProfanityOption=masked
